{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import rand\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import implementations as imp\n",
    "import proj1_helpers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = np.load('embeddings.npy')\n",
    "y = pickle.load(open('cooc.pkl', 'rb'))\n",
    "vocab = pickle.load(open('vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(21161, 20)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 0.56403988 -0.33822548  0.11260476  0.05975893 -0.39520949 -0.2375117\n",
      " -0.12390807 -0.16872797 -0.02044019  0.32865794 -0.64644995 -0.08901839\n",
      "  0.26161983 -0.1631089   0.08588484  0.57699542 -0.52317936 -0.37408539\n",
      " -0.13934747 -0.61597906]\n"
     ]
    }
   ],
   "source": [
    "print(glove[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thibault = list(zip(y.row, y.col, y.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['<user>', '<user>', 207302], ['!', '<user>', 73069], ['i', '<user>', 57298], ['the', '<user>', 30095], ['.', '<user>', 37914], [',', '<user>', 31220], ['to', '<user>', 34338], ['you', '<user>', 42215], ['(', '<user>', 8646], ['<url>', '<user>', 7980], ['a', '<user>', 23651], ['...', '<user>', 10669], ['and', '<user>', 21441], ['my', '<user>', 18235], ['me', '<user>', 20487], ['of', '<user>', 11016], ['?', '<user>', 24963], ['is', '<user>', 12825], ['for', '<user>', 14617], ['in', '<user>', 12590], ['it', '<user>', 17626], ['\"', '<user>', 16643], ['this', '<user>', 7707], ['so', '<user>', 11216], ['-', '<user>', 5440], ['with', '<user>', 8600], ['on', '<user>', 10289], ['that', '<user>', 11599], [')', '<user>', 8376], ['be', '<user>', 9940], [\"i'm\", '<user>', 10328], ['have', '<user>', 10408], [':', '<user>', 4367], ['but', '<user>', 9315], ['just', '<user>', 8257], ['rt', '<user>', 19209], ['love', '<user>', 7683], ['your', '<user>', 8459], ['all', '<user>', 5858], ['not', '<user>', 7353], ['was', '<user>', 7349], ['at', '<user>', 6317], ['are', '<user>', 6995], ['..', '<user>', 7297], ['like', '<user>', 6457], ['/', '<user>', 2865], ['get', '<user>', 5778], ['up', '<user>', 4879], ['frame', '<user>', 19], ['&', '<user>', 5005], ['lol', '<user>', 8229], ['know', '<user>', 6482], ['good', '<user>', 5879], ['do', '<user>', 5733], ['u', '<user>', 7978], ['now', '<user>', 5087], ['when', '<user>', 4245], ['one', '<user>', 4992], ['if', '<user>', 4988], ['we', '<user>', 6646], ['follow', '<user>', 7928], ['no', '<user>', 5376], ['can', '<user>', 5447], ['what', '<user>', 5006], ['go', '<user>', 4548], [\"don't\", '<user>', 4829], ['out', '<user>', 4303], ['x', '<user>', 3934], ['will', '<user>', 5276], ['day', '<user>', 3692], [\"'\", '<user>', 3158], ['please', '<user>', 6190], ['from', '<user>', 3227], ['see', '<user>', 5089], ['too', '<user>', 5605], ['want', '<user>', 3402], ['there', '<user>', 3511], ['back', '<user>', 4060], [\"it's\", '<user>', 4015], ['today', '<user>', 2691], ['about', '<user>', 3492], ['really', '<user>', 3485], ['how', '<user>', 3569], ['got', '<user>', 3570], ['thanks', '<user>', 6048], ['2', '<user>', 2010], [\"can't\", '<user>', 3476], ['time', '<user>', 3106], ['its', '<user>', 3614], ['think', '<user>', 3279], ['im', '<user>', 3307], ['*', '<user>', 3926], ['haha', '<user>', 4766], ['going', '<user>', 2793], ['he', '<user>', 3155], ['<3', '<user>', 3884], ['as', '<user>', 2831], ['miss', '<user>', 3401], ['by', '<user>', 2063], ['need', '<user>', 2620]]\n"
     ]
    }
   ],
   "source": [
    "print(list(map(lambda t : [inv_vocab[t[0]], inv_vocab[t[1]], t[2]], thibault[:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_id_tweet (list_tweets) :\n",
    "    ids = [x.split(',')[0] for x in list_tweets]\n",
    "    tweets =  [','.join(x.split(',')[:1]) for x in list_tweets]\n",
    "    return ids , tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "smile = []\n",
    "with open('twitter-datasets/train_neg_full.txt', encoding='UTF-8') as f :\n",
    "    ids , read = split_id_tweet(f.readlines())\n",
    "    smile = [-1] * len(read)\n",
    "    tweets_train = read\n",
    "    \n",
    "with open('twitter-datasets/train_pos_full.txt', encoding='UTF-8') as f :\n",
    "    ids , read = split_id_tweet(f.readlines())\n",
    "    smile += [1] * len(read)\n",
    "    tweets_train += read\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_vector = len(vocab)\n",
    "def to_vector (line) :\n",
    "    res= [0] * size_vector\n",
    "    for word in line.split(' ') :\n",
    "        change_nb = vocab.get(word)\n",
    "        if change_nb != None :\n",
    "            res[change_nb] = 1\n",
    "    return res\n",
    "        \n",
    "#tweets_res = [ np.array(to_vector(line)).dot(glove) for line in tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_three (idx , line ) :\n",
    "    res_set= []\n",
    "    res = []\n",
    "    for word in line.split(' ') :\n",
    "        change_nb = vocab.get(word)\n",
    "        if change_nb != None :\n",
    "            res_set += [change_nb]\n",
    "    for change_nb in set(res_set) :\n",
    "        res += [[1 , idx , change_nb]]\n",
    "    return res\n",
    "#tweets_to_sparse = [ np.array(elem) for idx , line in enumerate(tweets,0) for elem in to_three(idx , line)]\n",
    "\n",
    "def columns ( matrix , i) :\n",
    "    return [x[i] for x in matrix]\n",
    "\n",
    "\n",
    "def tweet_to_matrix ( tweets ) :\n",
    "    tweets_to_sparse = [ np.array(elem) for idx , line in enumerate(tweets,0) for elem in to_three(idx , line)]\n",
    "    \n",
    "    sparse_tweets = coo_matrix((columns(tweets_to_sparse,0) , (columns(tweets_to_sparse,1),columns(tweets_to_sparse,2))) , shape=(len(tweets), len(glove)))\n",
    "    return sparse_tweets.dot(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_tweets = coo_matrix((columns(0) , (columns(1),columns(2))) , shape=(len(tweets), len(glove)))\n",
    "#tweets_res = sparse_tweets.dot(glove)\n",
    "tweets_res = tweet_to_matrix(tweets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5989, 2500000, 0.0023956, 2500000)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for x in tweets_res :\n",
    "    count2 +=1\n",
    "    if  np.count_nonzero(x) == 0 :\n",
    "        count +=1\n",
    "count , len(tweets_res) , count/len(tweets_res) , count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,loss = imp.least_squares(np.array(smile), tweets_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.00497053, -0.00257374,  0.03705977, -0.00192451, -0.03340073,\n",
       "       -0.02537296,  0.00685164, -0.01524033,  0.00786395, -0.01178066,\n",
       "        0.00888847, -0.00923736, -0.01688849, -0.03289105, -0.00933731,\n",
       "       -0.0018966 , -0.00220792,  0.01008644,  0.01424898,  0.00859098])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_test=[]\n",
    "tweets_test=[]\n",
    "with open('twitter-datasets/test_data.txt') as f :\n",
    "    ids , tweets_test = split_id_tweet(f.readlines())\n",
    "    \n",
    "tweets_res_test = tweet_to_matrix(tweets_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9608, 10000, 0.9608, 10000)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for x in tweets_res_test :\n",
    "    count2 +=1\n",
    "    if  np.count_nonzero(x) == 0 :\n",
    "        count +=1\n",
    "count , len(tweets_res_test) , count/len(tweets_res_test) , count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tweets_res_test.dot(w)\n",
    "res = np.sign(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.create_csv_submission(ids,res,'results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(9608, 10000, 0.9608)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count = 0\n",
    "for x in res :\n",
    "    if x  == 0 :\n",
    "        count +=1\n",
    "count , len(res) , count/len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
