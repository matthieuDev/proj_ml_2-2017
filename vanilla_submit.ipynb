{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from scipy.sparse import rand\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.model_selection import learning_curve\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy.sparse import coo_matrix\n",
    "\n",
    "import implementations as imp\n",
    "import proj1_helpers as ph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "glove = np.load('embeddings.npy')\n",
    "y = pickle.load(open('cooc.pkl', 'rb'))\n",
    "vocab = pickle.load(open('vocab.pkl', 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "glove.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(glove[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "thibault = list(zip(y.row, y.col, y.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inv_vocab = {v: k for k, v in vocab.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(list(map(lambda t : [inv_vocab[t[0]], inv_vocab[t[1]], t[2]], thibault[:100])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_id_tweet (list_tweets) :\n",
    "    ids = [x.split(',')[0] for x in list_tweets]\n",
    "    tweets =  [','.join(x.split(',')[1:]) for x in list_tweets]\n",
    "    return ids , tweets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweets = []\n",
    "smile = []\n",
    "with open('twitter-datasets/train_neg_full.txt', encoding='UTF-8') as f :\n",
    "    ids , read = split_id_tweet(f.readlines())\n",
    "    smile = [-1] * len(read)\n",
    "    tweets_train = read\n",
    "    \n",
    "with open('twitter-datasets/train_pos_full.txt', encoding='UTF-8') as f :\n",
    "    ids , read = split_id_tweet(f.readlines())\n",
    "    smile += [1] * len(read)\n",
    "    tweets_train += read\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(tweets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "size_vector = len(vocab)\n",
    "def to_vector (line) :\n",
    "    res= [0] * size_vector\n",
    "    for word in line.split(' ') :\n",
    "        change_nb = vocab.get(word)\n",
    "        if change_nb != None :\n",
    "            res[change_nb] = 1\n",
    "        \n",
    "    return res\n",
    "        \n",
    "#tweets_res = [ np.array(to_vector(line)).dot(glove) for line in tweets]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_three (idx , line ) :\n",
    "    res_set= []\n",
    "    res = []\n",
    "    for word in line.split(' ') :\n",
    "        change_nb = vocab.get(word)\n",
    "        if change_nb != None :\n",
    "            res_set += [change_nb]\n",
    "    for change_nb in set(res_set) :\n",
    "        res += [[1 , idx , change_nb]]\n",
    "    return res\n",
    "#tweets_to_sparse = [ np.array(elem) for idx , line in enumerate(tweets,0) for elem in to_three(idx , line)]\n",
    "\n",
    "def columns ( matrix , i) :\n",
    "    return [x[i] for x in matrix]\n",
    "\n",
    "\n",
    "def tweet_to_matrix ( tweets ) :\n",
    "    tweets_to_sparse = [ np.array(elem) for idx , line in enumerate(tweets,0) for elem in to_three(idx , line)]\n",
    "    \n",
    "    sparse_tweets = coo_matrix((columns(tweets_to_sparse,0) , (columns(tweets_to_sparse,1),columns(tweets_to_sparse,2))) , shape=(len(tweets), len(glove)))\n",
    "    return sparse_tweets.dot(glove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sparse_tweets = coo_matrix((columns(0) , (columns(1),columns(2))) , shape=(len(tweets), len(glove)))\n",
    "#tweets_res = sparse_tweets.dot(glove)\n",
    "tweets_res = tweet_to_matrix(tweets_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for x in tweets_res :\n",
    "    count2 +=1\n",
    "    if  np.count_nonzero(x) == 0 :\n",
    "        count +=1\n",
    "count , len(tweets_res) , count/len(tweets_res) , count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w,loss = imp.least_squares(np.array(smile), tweets_res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ids_test=[]\n",
    "tweets_test=[]\n",
    "with open('twitter-datasets/test_data.txt') as f :\n",
    "    ids , tweets_test = split_id_tweet(f.readlines())\n",
    "    \n",
    "tweets_res_test = tweet_to_matrix(tweets_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "count2 = 0\n",
    "for x in tweets_res_test :\n",
    "    count2 +=1\n",
    "    if  np.count_nonzero(x) == 0 :\n",
    "        count +=1\n",
    "count , len(tweets_res_test) , count/len(tweets_res_test) , count2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = tweets_res_test.dot(w)\n",
    "res = np.sign(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imp.create_csv_submission(ids,res,'results.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count = 0\n",
    "for x in res :\n",
    "    if x  == 0 :\n",
    "        count +=1\n",
    "count , len(res) , count/len(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
